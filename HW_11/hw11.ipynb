{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Модуль 11. **Рекурентні нейронні мережі** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Завдання\n",
        "\n",
        "В якості домашнього завдання вам пропонується створити рекурентну нейронну мережу за допомогою механізмів Keras, яка буде класифікувати рецензії із датасету imdb.\n",
        "\n",
        "\n",
        "\n",
        "На відміну від прикладу в модулі 9 ми використаємо рекурентну нейронну мережу. Поекспериментуйте з будовою мережі - RNN, LSTM, двостороння та глибока.\n",
        "\n",
        "\n",
        "\n",
        "Порівняйте результати та зробіть висновки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install keras --upgrade tensorflow --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import imdb\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import (\n",
        "    Embedding,\n",
        "    Bidirectional,\n",
        "    LSTM,\n",
        "    GRU,\n",
        "    SimpleRNN,\n",
        "    Dense,\n",
        "    GlobalMaxPool1D,\n",
        "    Dropout,\n",
        ")\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "     Параметри "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_features = 10000  # кількість слів, що розглядаються як особливості\n",
        "maxlen = 500  # обмеження кількості слів в тексті\n",
        "\n",
        "epochs = 3\n",
        "batch_size = 128\n",
        "optimizer = \"adamw\"\n",
        "activation = \"sigmoid\"\n",
        "verbose = 1\n",
        "summary = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "     Завантаження даних "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Завантаження тренувальних та тестових даних зі вказанням обмеження на кількість слів\n",
        "(input_train, y_train), (input_test, y_test) = imdb.load_data(\n",
        "    num_words=max_features, skip_top=1000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Застосування заздалегідь обраної максимальної довжини до послідовних даних тренувального та тестового наборів\n",
        "input_train = pad_sequences(input_train, maxlen=maxlen)\n",
        "input_test = pad_sequences(input_test, maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"{input_train.shape = }\")\n",
        "print(f\"    {y_train.shape = }\")\n",
        "print(f\" {input_test.shape = }\")\n",
        "print(f\"     {y_test.shape = }\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "     Функція відображення графіків історії точності та втрат \n",
        "######      Аргументи: <br>1. history - дані історії точності та втрат<br>2. title - заголовок графіка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plt_history(\n",
        "    history, title=\"Точність та втрати на тренувальному та тестовому наборах\"\n",
        "):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    dict_data = {\n",
        "        \"acc\": \"Точність на тренувальному наборі\",\n",
        "        \"val_acc\": \"Точність на тестовому наборі\",\n",
        "        \"loss\": \"Втрати на тренувальному наборі\",\n",
        "        \"val_loss\": \"Втрати на тестовому наборі\",\n",
        "    }\n",
        "\n",
        "    epochs = range(1, len(history.history[\"acc\"]) + 1)\n",
        "\n",
        "    color_acc = \"royalblue\"\n",
        "    color_loss = \"peru\"\n",
        "    linestyle_train = \"--\"\n",
        "    linestyle_test = \"-\"\n",
        "\n",
        "    for data_, label_ in dict_data.items():\n",
        "        plt.plot(\n",
        "            epochs,\n",
        "            history.history[data_],\n",
        "            color=color_loss if (data_[-4:] == \"loss\") else color_acc,\n",
        "            linestyle=linestyle_test if (data_[:3] == \"val\") else linestyle_train,\n",
        "            label=label_,\n",
        "        )\n",
        "\n",
        "    plt.ylim(0, 1)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Епоха\")\n",
        "    plt.ylabel(\"Метрика\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "models, titles = [], [] # список моделей та їх назв"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "     Створення моделей "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "title_kgl = \"From Kaggle\"\n",
        "\n",
        "# model_rnn = Sequential()\n",
        "# # Додавання Embedding шару для перетворення слів в вектори фіксованої довжини\n",
        "# model_rnn.add(Embedding(max_features, 32))\n",
        "# # Параметри: кількість слів для розгляду як особливості та розмір вектора, що представляє кожне слово\n",
        "# model_rnn.add(SimpleRNN(32))\n",
        "# model_rnn.add(Dense(1, activation=activation))\n",
        "\n",
        "embed_size = 128\n",
        "model_kgl = Sequential()\n",
        "model_kgl.add(Embedding(max_features, embed_size))\n",
        "model_kgl.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "model_kgl.add(GlobalMaxPool1D())\n",
        "model_kgl.add(Dense(20, activation=\"relu\"))\n",
        "model_kgl.add(Dropout(0.05))\n",
        "model_kgl.add(Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "# model_kgl.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "titles.append(title_kgl)\n",
        "models.append(model_kgl)\n",
        "\n",
        "# batch_size = 100\n",
        "# epochs = 3\n",
        "# model_kgl.fit(X_t, y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simple Recurrent Neural Network (RNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "title_rnn = \"Simple Recurrent Neural Network (RNN)\"\n",
        "\n",
        "model_rnn = Sequential()\n",
        "# Додавання Embedding шару для перетворення слів в вектори фіксованої довжини\n",
        "model_rnn.add(Embedding(max_features, 32))\n",
        "# Параметри: кількість слів для розгляду як особливості та розмір вектора, що представляє кожне слово\n",
        "model_rnn.add(SimpleRNN(32))\n",
        "model_rnn.add(Dense(1, activation=activation))\n",
        "\n",
        "titles.append(title_rnn)\n",
        "models.append(model_rnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Long Short-Term Memory (LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "title_lstm = \"Long Short-Term Memory (LSTM)\"\n",
        "\n",
        "model_lstm = Sequential()\n",
        "# Додавання Embedding шару для перетворення слів в вектори фіксованої довжини\n",
        "model_lstm.add(Embedding(max_features, 32))\n",
        "# Параметри: кількість слів для розгляду як особливості та розмір вектора, що представляє кожне слово\n",
        "model_lstm.add(LSTM(32))\n",
        "model_lstm.add(Dense(1, activation=activation))\n",
        "\n",
        "titles.append(title_lstm)\n",
        "models.append(model_lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Gated Recurrent Unit (GRU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "title_gru = \"Gated Recurrent Unit (GRU)\"\n",
        "\n",
        "model_gru = Sequential()\n",
        "# Додавання Embedding шару для перетворення слів в вектори фіксованої довжини\n",
        "model_gru.add(Embedding(max_features, 32))\n",
        "# Параметри: кількість слів для розгляду як особливості та розмір вектора, що представляє кожне слово\n",
        "model_gru.add(GRU(32))\n",
        "model_gru.add(Dense(1, activation=activation))\n",
        "\n",
        "titles.append(title_gru)\n",
        "models.append(model_gru)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Bidirectional Recurrent Neural Network (BRNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# title_brnn = \"Bidirectional Recurrent Neural Network + LSTM (BRNN)\"\n",
        "\n",
        "# model_brnn = Sequential()\n",
        "# # Додавання Embedding шару для перетворення слів в вектори фіксованої довжини\n",
        "# model_brnn.add(Embedding(max_features, 32))\n",
        "# # Параметри: кількість слів для розгляду як особливості та розмір вектора, що представляє кожне слово\n",
        "# model_brnn.add(Bidirectional(LSTM(32)))\n",
        "# model_brnn.add(Dense(1, activation=activation))\n",
        "\n",
        "# titles.append(title_brnn)\n",
        "# models.append(model_brnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# title_brnn_s = \"Bidirectional Recurrent Neural Network + SimpleRNN (BRNN_2)\"\n",
        "\n",
        "# model_brnn_s = Sequential()\n",
        "# # Додавання Embedding шару для перетворення слів в вектори фіксованої довжини\n",
        "# model_brnn_s.add(Embedding(max_features, 32))\n",
        "# # Параметри: кількість слів для розгляду як особливості та розмір вектора, що представляє кожне слово\n",
        "# model_brnn_s.add(Bidirectional(SimpleRNN(32)))\n",
        "# model_brnn_s.add(Dense(1, activation=activation))\n",
        "\n",
        "# titles.append(title_brnn_s)\n",
        "# models.append(model_brnn_s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deep Recurrent Neural Network (DRNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# title_drnn = \"Deep Recurrent Neural Network + LSTM (DRNN)\"\n",
        "\n",
        "# model_drnn = Sequential()\n",
        "# # Додавання Embedding шару для перетворення слів в вектори фіксованої довжини\n",
        "# model_drnn.add(Embedding(max_features, 32))\n",
        "# # Параметри: кількість слів для розгляду як особливості та розмір вектора, що представляє кожне слово\n",
        "# model_drnn.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "# model_drnn.add(Bidirectional(LSTM(32)))\n",
        "# model_drnn.add(Dense(1, activation=activation))\n",
        "\n",
        "# titles.append(title_drnn)\n",
        "# models.append(model_drnn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# title_drnn_s = \"Deep Recurrent Neural Network + SimpleRNN (DRNN_2)\"\n",
        "\n",
        "# model_drnn_s = Sequential()\n",
        "# # Додавання Embedding шару для перетворення слів в вектори фіксованої довжини\n",
        "# model_drnn_s.add(Embedding(max_features, 32))\n",
        "# # Параметри: кількість слів для розгляду як особливості та розмір вектора, що представляє кожне слово\n",
        "# model_drnn_s.add(SimpleRNN(32, return_sequences=True))\n",
        "# model_drnn_s.add(SimpleRNN(32))\n",
        "# model_drnn_s.add(Dense(1, activation=activation))\n",
        "\n",
        "# titles.append(title_drnn_s)\n",
        "# models.append(model_drnn_s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "     Компіляція та навчання моделей "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "histories = []\n",
        "\n",
        "for i, model in enumerate(models):\n",
        "    print(f\"Training model {i+1} - \\033[33m{titles[i]}\\033[0m...\")\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "    if summary:\n",
        "        model.summary()\n",
        "\n",
        "    history = model.fit(\n",
        "        input_train,\n",
        "        y_train,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(input_test, y_test),\n",
        "        verbose=verbose,\n",
        "    )\n",
        "    histories.append(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, history in enumerate(histories):\n",
        "    plt_history(history, title=titles[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating a list for options\n",
        "train_acc, train_loss, val_acc, val_loss = [], [], [], []\n",
        "\n",
        "# Collecting results from stories\n",
        "for history in histories:\n",
        "    train_acc.append(history.history[\"acc\"][-1])\n",
        "    train_loss.append(history.history[\"loss\"][-1])\n",
        "    val_acc.append(history.history[\"val_acc\"][-1])\n",
        "    val_loss.append(history.history[\"val_loss\"][-1])\n",
        "\n",
        "# Creating a DataFrame\n",
        "df = pd.DataFrame(\n",
        "    {\n",
        "        \"Model\": titles,\n",
        "        \"Train Accuracy\": train_acc,\n",
        "        \"Train Loss\": train_loss,\n",
        "        \"Validation Accuracy\": val_acc,\n",
        "        \"Validation Loss\": val_loss,\n",
        "    }\n",
        ")\n",
        "\n",
        "df.head(len(models))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "\n",
        "#### **Висновки:**\n",
        "\n",
        "#### У всіх варіантах моделей ми спостерігали високу точність та низьки втрати на даних навчання. Це означає, що моделі ефективно навчаються та здатні добре адаптуватися до навчальних даних.\n",
        "\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ds-rEpFRPgy-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
